
# Sign Language to Text and Speech Conversion ğŸ¤ŸğŸ—£ï¸  
A real-time system for converting American Sign Language gestures into **text and speech**, using **deep learning**, **OpenCV**, and a **custom Tkinter-based GUI**.

[![Demo Video](https://img.shields.io/badge/Watch-Demo-blue)](link-to-video)  
ğŸ”— **GitHub**: [github.com/jashan7167/SignLanguageDetection](https://github.com/jashan7167/SignLanguageDetection)

---

## ğŸ“Œ Features

- ğŸ”¤ Converts American Sign Language (ASL) alphabet gestures to text
- ğŸ—£ï¸ Converts the detected text to speech
- ğŸ“· Real-time webcam-based gesture capture
- ğŸ§  Deep learning model trained on 8 grouped classes
- ğŸ–¥ï¸ Custom GUI built with **Tkinter** (previously PyQt5)
- âœ‹ Special â€œOpen Handâ€ gesture to **break a character** and move to the next one
- ğŸ§ª Post-model **gesture refinement using if-else logic** for better accuracy

---

## ğŸ“½ï¸ Demonstration

[](./Images/a.png)

#####  Gesture of  'A' being detected and converted to text
> â¬‡ï¸ **Insert a screenshot here showing a complete word being formed**

```
ğŸ“¸ ![Formed Word Screenshot](link-to-image)
```

> â¬‡ï¸ **Insert video demonstration link below**

```
ğŸ¥ [Click to watch the demo video](link-to-your-demo)
```

---

## ğŸ§  Grouped Gesture Model

To reduce model complexity and increase accuracy, we grouped similar signs into **8 logical classes**, then refined them using conditional rules.

- **Group 0**: A, E, M, N, S, T  
- **Group 1**: B, D, F, I, K, R, U, V, W  
- **Group 2**: C, O  
- **Group 3**: G, H  
- **Group 4**: L, X  
- **Group 5**: P, Q, Z  
- **Group 6**: X (alternative conditions)  
- **Group 7**: Y, J

---

## ğŸ› ï¸ Tech Stack

| Component            | Tool/Library         |
|---------------------|----------------------|
| Programming Language | Python 3.x           |
| GUI                  | Tkinter              |
| ML Model             | CNN (Keras, TensorFlow) |
| Image Capture        | OpenCV               |
| Voice Output         | pyttsx3              |
| Model File           | `cnn8grps_rad1_model.h5` |

---

## ğŸ—ï¸ System Architecture

1. **Live feed via webcam** using OpenCV  
2. **Hand gesture prediction** using trained CNN model  
3. **Group decoding** and refined using custom `if-else` logic  
4. **Character conversion & display on GUI**  
5. **Speech synthesis** for the predicted output  

---

## ğŸ”„ Why Tkinter over PyQt5?

Initially developed using **PyQt5**, we shifted to **Tkinter** due to:

- Faster GUI rendering and better performance  
- Lighter footprint for packaging and execution  
- Easier customization for dynamic updates  
- PyQt5 was sometimes laggy and overcomplicated for our minimal use case

---

## âœ‹ Open Hand Gesture (Space Breaker)

- We designed an **Open Hand Gesture** as a trigger to **finalize a character**  
- After many trials, it was made responsive through shape & motion thresholds  
- Detected using pixel ratios and position in the ROI  
- **Breaks the current letter** and moves to the next automatically  
> âœ… Improves natural typing experience with sign language

---

## ğŸ“‚ Project Structure

```
ğŸ“ Sign-Language-To-Text-and-Speech-Conversion
â”œâ”€â”€ AtoZ_3.1/                 # Data directory
â”œâ”€â”€ cnn8grps_rad1_model.h5    # Trained CNN model (8 groups)
â”œâ”€â”€ data_collection_*.py      # Scripts for data collection
â”œâ”€â”€ final_pred.py             # Main script with GUI and gesture prediction
â”œâ”€â”€ Model.ipynb               # Jupyter notebook (model training)
â”œâ”€â”€ prediction_wo_gui.py      # Script to test model without GUI
â”œâ”€â”€ white.jpg                 # Background placeholder image
```

---

## ğŸ§ª Testing and Refinement

- **Tested each grouped gesture individually**
- Added **hardcoded logic** for characters often confused (e.g., M vs. N)
- Alternative gesture libraries were tried (e.g., MediaPipe, Handtrack.js), but lacked accuracy, so we opted for model + rules

---

## ğŸ“ˆ Future Work

- Expand dataset to include full **words and phrases**
- Add **dynamic gesture tracking** for complete sentences
- Convert to **mobile or web-based deployment**
- Include support for **gesture correction/undo**

---

## ğŸ‘¥ Team

- Jashanjot Singh
- Divyanshu Pandey
- Himanshu Sharma

---

